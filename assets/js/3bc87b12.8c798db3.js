"use strict";(self.webpackChunkcs_639_website=self.webpackChunkcs_639_website||[]).push([[272],{3905:(e,t,n)=>{n.d(t,{Zo:()=>h,kt:()=>u});var i=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function r(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,i,a=function(e,t){if(null==e)return{};var n,i,a={},o=Object.keys(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)n=o[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var c=i.createContext({}),l=function(e){var t=i.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):r(r({},t),e)),n},h=function(e){var t=l(e.components);return i.createElement(c.Provider,{value:t},e.children)},d="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},m=i.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,c=e.parentName,h=s(e,["components","mdxType","originalType","parentName"]),d=l(n),m=a,u=d["".concat(c,".").concat(m)]||d[m]||p[m]||o;return n?i.createElement(u,r(r({ref:t},h),{},{components:n})):i.createElement(u,r({ref:t},h))}));function u(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,r=new Array(o);r[0]=m;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s[d]="string"==typeof e?e:a,r[1]=s;for(var l=2;l<o;l++)r[l]=n[l];return i.createElement.apply(null,r)}return i.createElement.apply(null,n)}m.displayName="MDXCreateElement"},6252:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>r,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var i=n(7462),a=(n(7294),n(3905));const o={id:"Introduction",sidebar_position:1},r="Introduction",s={unversionedId:"Introduction",id:"Introduction",title:"Introduction",description:"In this project, the goal is to explore and research how we could use deep learning to enhance low light images. Low-light image enhancement has wild applications in our daily life and in different scientific research fields such as night surveillance, automated driving, fluorescence microscopy, etc. This technique can improve the usefulness of an image to satisfy human viewing. Also, it can make low-light images applicable for applications in autonomous driving, scientific data capture, and general visual enhancement. For example, self-driving car can see humans in the dark environment to prevent accidents from happening with this technology. Therefore, low-light image enhancement is very significant and is worth studying. With more application applied machine/deep learning methods for improvement, we\u2019d like to research how to use deep learning to enhance low-light images.",source:"@site/docs/1-Introduction.md",sourceDirName:".",slug:"/Introduction",permalink:"/CS639-Website/docs/Introduction",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/1-Introduction.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"Introduction",sidebar_position:1},sidebar:"tutorialSidebar",next:{title:"Related Work",permalink:"/CS639-Website/docs/Related-Work"}},c={},l=[{value:"Dataset",id:"dataset",level:2}],h={toc:l};function d(e){let{components:t,...o}=e;return(0,a.kt)("wrapper",(0,i.Z)({},h,o,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"introduction"},"Introduction"),(0,a.kt)("p",null,"In this project, the goal is to explore and research how we could use deep learning to enhance low light images. Low-light image enhancement has wild applications in our daily life and in different scientific research fields such as night surveillance, automated driving, fluorescence microscopy, etc. This technique can improve the usefulness of an image to satisfy human viewing. Also, it can make low-light images applicable for applications in autonomous driving, scientific data capture, and general visual enhancement. For example, self-driving car can see humans in the dark environment to prevent accidents from happening with this technology. Therefore, low-light image enhancement is very significant and is worth studying. With more application applied machine/deep learning methods for improvement, we\u2019d like to research how to use deep learning to enhance low-light images."),(0,a.kt)("p",null,"Regardless of the technological advancements, there is still a long way to improve this task. Low-light images typically suffer from two problems which are low visibility and high noise. Low visibility shows that the image has small pixel values due to few amount of photon, and high noise would dominate and disrupt the image content, so the overall signal-to-noise ratio is low."),(0,a.kt)("p",null,"After doing some research on ",(0,a.kt)("em",{parentName:"p"},(0,a.kt)("a",{parentName:"em",href:"https://github.com/dawnlh/awesome-low-light-image-enhancement"},"Awesome Low Light Image Enhancement")),", a GitHub repository which provides a list of resources related to low light image enhancement, we adopt the KinD algorithm proposed by Zhang et al. ","[5]"," and we re-implement this method with Pytorch (original work is implemented with TensorFlow). We have achieved similar performance like original work, analyzed its strength and weakness, and pointed out some directions for future work. "),(0,a.kt)("h2",{id:"dataset"},"Dataset"),(0,a.kt)("p",null,"The dataset we used is LOLDataset ","[6]"," which contains a total of 485 low-light and high-light paired training images and 15 testing pairs. Here you can see an example of training paired images, the left one is the low-light image and the right one is the high-light image."),(0,a.kt)("img",{style:{float:"left",width:"50%"},src:n(4569).Z}),(0,a.kt)("img",{style:{float:"right",width:"50%"},src:n(1378).Z}))}d.isMDXComponent=!0},1378:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/train_high_40-db0e0970db4182c5b21c288c63523e92.png"},4569:(e,t,n)=>{n.d(t,{Z:()=>i});const i=n.p+"assets/images/train_low_40-a3b3ffc6360c73af78a3a39cf5eccb69.png"}}]);