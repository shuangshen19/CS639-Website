"use strict";(self.webpackChunkcs_639_website=self.webpackChunkcs_639_website||[]).push([[166],{3905:(e,t,r)=>{r.d(t,{Zo:()=>d,kt:()=>h});var n=r(7294);function o(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function a(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?a(Object(r),!0).forEach((function(t){o(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):a(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function s(e,t){if(null==e)return{};var r,n,o=function(e,t){if(null==e)return{};var r,n,o={},a=Object.keys(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||(o[r]=e[r]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(n=0;n<a.length;n++)r=a[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(o[r]=e[r])}return o}var l=n.createContext({}),c=function(e){var t=n.useContext(l),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},d=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},u="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},m=n.forwardRef((function(e,t){var r=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),u=c(r),m=o,h=u["".concat(l,".").concat(m)]||u[m]||p[m]||a;return r?n.createElement(h,i(i({ref:t},d),{},{components:r})):n.createElement(h,i({ref:t},d))}));function h(e,t){var r=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=r.length,i=new Array(a);i[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:o,i[1]=s;for(var c=2;c<a;c++)i[c]=r[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}m.displayName="MDXCreateElement"},9020:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>u,frontMatter:()=>a,metadata:()=>s,toc:()=>c});var n=r(7462),o=(r(7294),r(3905));const a={sidebar_position:2},i="Related Work",s={unversionedId:"Related-Work",id:"Related-Work",title:"Related Work",description:"Before the prevalent of deep learning, people tried to do low-light image enhancement by histogram equalization and gamma correciton. Since these method didn't really modify the brightness on pure illumination factor. It turns out that some unpleasant artifacts are introduced. Besides, people adopted retinex theory to extract illumination term and processed it to modify the brightness. However, since it was not easy to design an algorithm to perform retinex theory, the results also suffered from issues like over-enhancement.",source:"@site/docs/2-Related-Work.md",sourceDirName:".",slug:"/Related-Work",permalink:"/CS639-Website/docs/Related-Work",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/2-Related-Work.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Introduction",permalink:"/CS639-Website/docs/Introduction"},next:{title:"Method",permalink:"/CS639-Website/docs/Method"}},l={},c=[],d={toc:c};function u(e){let{components:t,...r}=e;return(0,o.kt)("wrapper",(0,n.Z)({},d,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("h1",{id:"related-work"},"Related Work"),(0,o.kt)("p",null,"Before the prevalent of deep learning, people tried to do low-light image enhancement by histogram equalization and gamma correciton. Since these method didn't really modify the brightness on pure illumination factor. It turns out that some unpleasant artifacts are introduced. Besides, people adopted retinex theory to extract illumination term and processed it to modify the brightness. However, since it was not easy to design an algorithm to perform retinex theory, the results also suffered from issues like over-enhancement."),(0,o.kt)("p",null,"As computing resource becomes more powerful, people start using deep learning method for low-light image enhancement. Lore et al. ","[2]"," propose a deep autoencoder-based approach LLNET to identify signal features from low-light images and adaptively brighten images without over-amplifying/saturating the lighter parts in images with a high dynamic range. LLNET shows that a variant of the stacked-sparse denoising autoencoder (SSDA), which are a sparsity-inducing variant of deep autoencoders that ensures learning the invariant features embedded in the proper dimensional space of the dataset in an unsupervised manner, can learn from underlying signal characteristics/synthetically darkened and noise-added training examples to adaptively enhance images taken from natural low-light environment."),(0,o.kt)("p",null,"Since it is hard to collect training data with low-light and normal-light images, Jiang et al. ","[3]"," use GAN (Generative Adversarial Network) to do unsupervised learning. They use information extracted from input to regularize training. In this model, there are one generator and two discriminators. For the generator, it adopt U-Net ","[4]"," with attention mechanism to get multi-level features with rich texture information so that generator can generates real enough images to fake discriminators. As for discriminators, one is local and the other is global. Global discriminator is responsible for discriminating real or fake on image-level, while local discriminator is for local patch level. With this structure, the network can prevent over- or under-enhancement in local region."))}u.isMDXComponent=!0}}]);